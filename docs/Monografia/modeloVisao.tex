\subsection{Modelo de Observação da Visão}\label{subsec:modeloVisao}

O uso de visão é muito interessante para a obtenção da localização pois uma câmera de vídeo é capaz de captar uma grande quantidade de estímulos visuais. Dentre os vários tipos de estímulos, optou-se, baseado em \cite{barra}, como principal estímulo retas verticais presentes nos ambientes, tais como batentes de portas, colunas, janelas, etc. A denominação \textsl{reta vertical} será dada às retas presentes no mundo real, enquanto \textsl{projeções} são as observações dessas retas nas imagens.

Neste trabalho, emprega-se a visão monocular, cujo sensor é uma câmera de vídeo montada sobre o robô, apontada na direção frontal dele. 

\subsubsection{Modelo da Câmera}
Dada a característica de baixo custo desejada, a câmera usada é uma \textit{webcam} convencional, baseada na tecnologia CCD. O modelo da câmera segui o modelo de câmera de orifício, também conhecido como \textit{pinhole}. Neste modelo, a câmera possui um centro focal C e um plano de projeção, onde as imagens são formadas, representado como um espaço discreto cujo tamanho indica a resolução da câmera e cada elemento discreto é um pixel da imagem. 

\begin{figure}[htbp]
	\centering
		\includegraphics{imagens/pinhole.jpg}
	\caption{Modelo de câmera pinhole, composto pelo centro focal C e pelo plano de projeção (figura retirada de \cite{barra})}
	\label{fig:pinhole}
\end{figure}


As cores são representadas segundo o modelo RGB, em que uma cor é descrita por meio das intensidades nos componentes vermelho, verde e azul do espectro de luz. 


Considera-se o sistema de coordenadas $\left( X_c, Y_c, Z_c \right)$ intrínseco à câmera. Um ponto qualquer do espaço pode ser representado nesse sistema como ${\bf p_{cam}} = \left[ x_{cam}, y_{cam}, z_{cam} \right]^T$, enquanto sua projeção no plano de projeção da câmera é dada por ${\bf p_{proj}} = \left[ u, v \right]^T$. As coordenadas de ${\bf p_{proj}}$ podem ser obtidas segundo as equações abaixo:

\begin{equation}
	u = f_u \frac{y_{cam}}{x_{cam}} + u_0
	\label{coordu:pinhole}
\end{equation}

\begin{equation}
	v = f_v \frac{z_{cam}}{x_{cam}} + v_0
	\label{coordv:pinhole}
\end{equation}

onde $f_u$ e $f_v$ indicam a distância focal da câmera horizontal e vertical, respectivamente, cujos valores são obtidos em uma etapa de calibração da câmera, assim como os valores de $u_0$ e $v_0$, que indicam o centro do plano de projeção, no sistema de coordenadas do plano de projeção $\left(U, V\right)$. Os valores de $u$ e $v$ são dados em pixels. 

Já um ponto no sistema de coordenadas global, isto é, no mesmo sistema de coordenadas na qual a postura do robô é representada, dado por ${\bf p_real} = \left[x, y, z\right]^T$, precisa ser previamente convertido para o sistema de coordenadas intrínseco à câmera, resultando em um ponto ${\bf p_cam} = \left[ x_{cam}, y_{cam}, z_{cam} \right]^T$, antes que as equações acima possam ser aplicadas. Tal conversão é feita por meio de:

\begin{equation}
	{\bf p_{cam}} = {\bf R^T\left( p_{real} - C \right)}
\end{equation}
	
onde ${\bf R}$ é o parâmetro de rotação relativa entre o sistema de coordenadas da câmera e o global, enquanto ${\bf C}$ é a translação entre esses sistemas de coordenadas. Assim como $f_u$ e $f_v$, ${\bf R}$ e ${\bf C}$ também são determinados durante a calibração da câmera.
	

\subsubsection{Realce de Projeções Verticais}

A primeira etapa do processamento da visão é ressaltar, nos quadros obtidos pela câmera, apenas os pixels que possam pertencer à projeções de retas verticais. Isso é feito através do uso de um Operador de Sobel modificado.

O Operador de Sobel é um algoritmo voltado para a detecção de bordas em imagens, cujo resultado é uma imagem em tons de cinza onde os pixels que representam bordas de objetos ficam demarcados em branco enquanto os demais assumem a tons próximos ao preto. 

Vale ressaltar que o Operador de Sobel é um tipo de convolução de imagens. A ideia básica da convolução de imagens, que é discreta e bidimensional, é a de uma janela que é deslizada sobre a imagem. O valor do pixel resultante é igual à soma ponderada dos pixels da imagem original que se encontram dentro da janela. Os pesos são os valores do filtro que foram estabelecidos para cada um dos pixels da janela. Tal janela é denominada \textit{kernel} da convolução. O Operador de Sobel permite que seu filtro seja divido em dois, sendo um para a direção horizontal e o outro, para a vertical.

Uma vez que o estímulo de interesse são as projeções verticais, utiliza-se apenas o filtro horizontal do Operador de Sobel. Como dito anteriormente, foi utilizado uma versão modificada do filtro, cujos valores foram determinados empiricamente considerando-se dois parâmetros: precisão na demarcação das retas verticais e desempenho, uma vez que aplicar a convolução sobre uma imagem é um processo computacionalmente pesado. Assim, o filtro obtido apresenta a seguinte matriz:

\begin{equation}
	{\bf filtro_{vertical}} = \left(
		\begin{matrix}
			2 & 0 & -2 \\
	        2 & 0 & -2 \\
	        2 & 0 & -2 \\
	        2 & 0 & -2 \\
	        2 & 0 & -2 \\
	        2 & 0 & -2 \\
	        2 & 0 & -2
		\end{matrix}
	\right)
\end{equation}

É importante salientar que antes do Operador de Sobel ser aplicado, a imagem sofre uma operação de borramento, cujo objetivo é reduzir a influência que o ruído presente na captura das imagens possa ter sobre a qualidade do resultado do Operador de Sobel.

\begin{figure}[ht]
	\centering
		\includegraphics[width=.6\columnwidth]{imagens/corredor.jpg}
	\caption{Foto tirada no corredor das salas C2}%
	\label{visao:original}
\end{figure}

\begin{figure}[ht]
	\centering
		\includegraphics[width=.6\columnwidth]{imagens/sobel.jpg}
	\caption{Imagem obtida após a aplicação do Operador de Sobel modificado sobre a Figura~\ref{visao:original}}
	\label{visao:convolucao}
\end{figure}


\subsubsection{Perfil de Cor}

O perfil de cor segue a hipótese que a distribuição de cores ao redor das retas verticais contém informação suficiente para ajudar a identificar projeções de uma mesma reta vertical em diferentes quadros do vídeo.

Ele considera uma região da imagem centrada na sequência de pixels que pertencem a uma projeção, estendendo-se por uma faixa de \textit{n} pixels a direita e a esquerda de cada pixel da projeção.

As informações que se mostraram relevantes sobre o perfil de cor são os valores médios, para cada componente de cor, denominados $R_{esq}$, $R_{dir}$, $G_{esq}$, $G_{dir}$, $B_{esq}$ e $B_{dir}$ dos lados esquerdo e direito em relação ao centro da região.

A comparação de dois perfis de cor resulta num fator de correlação normalizado que indica quão semelhantes são os perfis. O cálculo desse fator segue as seguintes equações:

\begin{eqnarray*}
R & = & \left( \delta - \vert R^{(1)}_{esq} - R^{(2)}_{esq} \vert \right) + \left( \delta - \vert R^{(1)}_{dir} - R^{(2)}_{dir} \vert \right) \\
G & = & \left( \delta - \vert G^{(1)}_{esq} - G^{(2)}_{esq} \vert \right) + \left( \delta - \vert G^{(1)}_{dir} - G^{(2)}_{dir} \vert \right) \\
B & = & \left( \delta - \vert B^{(1)}_{esq} - B^{(2)}_{esq} \vert \right) + \left( \delta - \vert B^{(1)}_{dir} - B^{(2)}_{dir} \vert \right)
\end{eqnarray*}
\begin{displaymath}
C = \frac{\left( R + G + B \right)}{6\delta} 
\label{eqn:perfilcor}
\end{displaymath}

onde $\delta$ é a maior diferença esperada entre os componentes, $R$, $G$ e $B$ são representam as diferenças nas intensidades dos componentes de cor entre o lado direito e esquerdo, em relação à reta considerada, e $C$ é o fator de correlação. 


\subsubsection{Detecção de Projeções Verticais}

A partir da imagem resultante da etapa anterior, onde existem apenas linhas verticais demarcada, as projeções são detectadas e suas posições na imagem são determinadas, juntamente com outros parâmetros que são citados abaixo.

Antes de iniciar a detecção, aplica-se um procedimento que filtra pixels que não são máximos locais, isto é, dada uma pequena porção da imagem, a intensidade de um pixel não é a maior dessa região. Já que a tendência da etapa de extração é marcar os pixels mais próximos do centro de uma linha vertical com valores maiores que os pixels periféricos da mesma linha, o procedimento aplicado faz com que uma possível projeção, antes representada na imagem como uma linha relativamente grossa (largura de vários pixels), passe a ter largura de um único pixel.

O procedimento de detecção é iniciado em um estado no qual a imagem é varrida, da esquerda para a direita, de cima para baixo, buscando um pixel que tenha intensidade maior do que um \textsl{limiar de início} ($lim_{inicio}$). Quando um pixel atende a esse requisito, passa-se a um estado secundário.

Neste novo estado, supõe-se que o pixel acima do limiar é um ponto pertencente a um nova projeção, adicionando-o a uma lista de pontos que compõem a projeção. A partir dele, a imagem passa a ser varrida na direção vertical, seguindo as seguintes regras: compara-se o valor dos três pixels vizinhos que estão diretamente abaixo do pixel recém-adicionado na nova possível projeção. O pixel que será adicionado na lista da projeção será aquele com o maior valor. Contudo, existem algumas ressalvas:
\begin{itemize}
\item se o pixel de maior valor for um dos inferiores laterais, entra em ação um fator de inércia vertical cujo papel é forçar a projeção a ser o mais vertical possível. Enquanto este fator estiver ativo, é dada preferência para o pixel diretamente abaixo, mesmo que seu valor não seja o maior. Esse fator será desativado quando alguns pixels não máximos forem selecionados, evitando, assim, a formação de um projeção distorcida.
\item se o maior valor for inferior a um \textsl{limiar de término} ($lim_{termino}$), o pixel é adicionado temporariamente à projeção e passa-se a contar quantos pixels abaixo do limiar foram inseridos em sequência. Caso essa contagem ultrapasse um valor máximo, todos os que foram adicionados temporariamente são removidos, a projeção obtida até então é considerada finalizada e o algoritmo de detecção volta ao estado inicial. Se após alguns pixels abaixo do limiar de término serem inseridos, mas com contagem menor do que a máxima permitida, for encontrado um pixel cuja intensidade é superior ao limiar de término, a adição deles é confirmada e a contagem é zerada.
\end{itemize}

Cada projeção detectada passa por algumas verificações, que incluem o tamanho da projeção, eliminando projeções muito pequenas, e a inclinação, descartando aquelas que não estão tão verticais quanto desejado. Aquelas que forem aceitas terão seus perfis de cor determinados, o que conclui a fase de detecção.

Ao final, cada projeção será representada a partir da posição no eixo horizontal do plano de projeção da câmera (coordenada $u_vert$) e seu respectivo perfil de cor.

\begin{figure}[ht]
	\centering
		\includegraphics[width=.6\columnwidth]{imagens/projections.jpg}
	\caption{Projeções detectadas, assinalada em vermelho, a partir da imagem apresentada na Figura ~\ref{visao:original}}
	\label{visao:projecoes}
\end{figure}

\subsubsection{Descrição de Marcos}

Um marco pode ser definido como uma reta vertical cuja posição no mundo real é conhecida. Sua representação inclui as coordenadas de sua posição ${\bf p_{marco}} = \left[x, y\right]$, no sistema de coordenadas absolutas (globais), e seu perfil de cor, que pode ser usado como forma de identificação.

Os marcos são usados, primeiramente, para que se tente estabelecer um vínculo entre projeções que estão sendo observadas com retas verticais do ambiente. Aqueles com os quais foi possível realizar uma associação são usados para atualizar a estimativa da postura do robô, conforme será mostrado posteriormente.


\subsubsection{Associação entre Projeções Verticais e Marcos}

A fase de associação visa determinar quais marcos conhecidos do ambiente estão sendo observados em um dado momento, a partir da lista de projeções detectadas no quadro da câmera. Ela pode ser segregada em três passos, conforme descrito a seguir.

\paragraph{Restrição de marcos}
Para reduzir o conjunto de marcos com os quais tentar-se-á estabelecer novas associações, e com isso, diminuindo a chance de ocorrerem falsos positivos, o conjunto de todos os marcos conhecidos do ambiente passa por um filtro que, usando a última postura conhecida do robô, calcula quais marcos estão dentro do campo de visão da câmera. 

Tendo-se determinado o ângulo $alfa_{cam}$ relativo a abertura do campo de visão da câmera, na horizontal, traça-se um setor circular de raio infinito, centrado nas coordenadas $\left[x, y\right]^T$ da postura do robô, apontando para a mesma direção indicada por $\theta$, com ângulo do setor igual a $alfa_{cam}$. Em seguida, é verificado se o ponto ${\bf p_{marco}} = \left[x_{marco}, y_{marco}\right]^T$ de cada marco encontra-se dentro desse setor circular. 

É importante observar que o filtro não remove marcos que possam estar ocluídos, já que o filtro não tem informações suficientes para tal procedimento, nem leva em consideração a distância entre o robô e o marco como um parâmetro de restrição, pois, apesar da probabilidade de uma associação ser concretizada diminui conforme essa distância aumenta, ela não pode ser completamente descartada neste passo inicial.


\paragraph{Janela de Busca por Previsão}
Novamente, a partir da última postura conhecida do robô, é possível prever a coordenada $u_{previsao}$ que a projeção vertical de um marco deveria estar localizada na imagem, usando a equação \ref{coordu:pinhole} do modelo de câmera de orifício. 

Para cada marco visível $i$, há uma janela de busca, centrada em $u^(i)_{previsao}$, com largura igual a $larg_{janela}$, em que apenas as projeções contidas nesse janela têm chance de serem associadas ao marco dono da janela. Portanto, a janela de busca atua como uma restrição por disposição espacial, reduzindo o número de comparações que precisarão ser feitas até a conclusão da associação.


\paragraph{Determinação da associação por Perfil de Cor}
As projeções que sobraram terão seus perfis de cor comparados com o do marco, resultando em valores que indicam o nível de correlação entre uma projeção e o marco. Tal comparação faz uso da equação \ref{eqn:perfilcor}. Uma associação entre projeção vertical e marco será concretizada se existir pelo menos um valor de correlação maior do que 0 e a projeção associada ao marco será aquela que apresentar o maior valor de correlação.


\subsubsection{Obtenção da observação esperada}

Após a fase de associações, tem-se a lista de marcos que estão sendo observados e que devem ser usados para atualizar a postura do robô. O próximo passo é fornecer ao filtro de Kalman estendido as informações de observação real obtida ${\bf z}$, os valores esperados para as observações ${\bf h}$, a matriz de covariância $\bm{R}$, e o jacobiano de ${\bf h}$, a matriz $\bm{H}$.

\paragraph{Cálculo da observação esperada}

Seja a postura do robô descrita como ${\bf {x}} = \left[ x, y, \theta\right]^T$ e ${\bf p^{(i)}_{marco}} = \left[ x^{(i)}_{marco}, y^{(i)}_{marco}\right]^T$ as coordenadas de cada marco \textit{i} observado, tem-se:

\begin{equation*}
h^{(i)}({\bf x}) = -f_u \frac{ \sin(\theta)\left(x^{(i)}_{marco} - x \right) + \cos( \theta) \left( y^{(i)}_{marco} - y \right) } { \cos(\theta) \left(x^{(i)}_{marco} - x \right) - \sin(\theta) \left( y^{(i)}_{marco} - y \right) } + u_0 
\end{equation*}

onde $f_u$ é a distância focal na direção horizontal enquanto $u_0$ é o centro horizontal do plano de projeção da câmera. Maiores detalhes sobre a determinação da equação $h\left( {\bf x} \right)$ podem ser obtidos em \cite{barra}.

O vetor ${\bf x}$ é composto pelo resultado da equação acima, aplicada sobre cada um dos marcos observados, tendo dimensão $1Xi$. 


\paragraph{Cálculo do jacobiano} A matriz $\bm{H}$ é necessária para que o EKF corrija a postura corretamente em cada componente. Ela é dada por:

\begin{equation*}
\bm{H} = \left. \frac{\partial h(\vec{x})}{\partial \vec{x}}\right|_{\hat{x}}
\end{equation*}

\begin{equation}
\bm{H} = 
	\left(
    	\begin{array}{>{\displaystyle}c}
    		f_u \frac{ \sin(\theta)Z - \cos(\theta)V}{Z^2} \\
    		\\
    		f_u \frac{ \cos(\theta)Z + \sin(\theta)V}{Z^2} \\
    		\\
    		f_u \left[ -\frac{V^2}{Z^2} + 1 \right]
		\end{array}
	\right)^T
\end{equation}

onde $V$ e $Z$ são variáveis auxiliares dadas por:

\begin{equation*}
	V = \sin(\theta)\left(x^{(i)}_{marco} - x \right) + \cos( \theta) \left( y^{(i)}_{marco} - y \right)
\end{equation*}

\begin{equation*}
	Z = \cos(\theta) \left(x^{(i)}_{marco} - x \right) - \sin(\theta) \left( y^{(i)}_{marco} - y \right)
\end{equation*}

Cada linha da matriz $\bm{H}$ diz respeito a um marco observado, devendo ter o número de linhas igual ao número de marcos. 

\paragraph{Cálculo da matriz de covariância} A matriz $\bm{R}$ é uma matriz quadrada que contém as covariâncias que são passadas para o EKF durante a etapa de atualização da estimativa. Sendo $n$ o número de marcos observadas em um determinado ciclo da visão, a matriz terá dimensão $nXn$, com os seguintes valores:

\begin{equation}
	R = 
	\left(
	\begin{matrix}
		\sigma^2_{obs} & 0 & 0 & \ldots \\
		0 & \sigma^2_{obs} & 0 & \ldots \\
		0 & 0 & \sigma^2_{obs} & \ldots \\
		\vdots & \vdots & \vdots & \ddots \\
	\end{matrix}
	\right)
\end{equation}

onde $\sigma^2_{obs}$ é a variância medida empiricamente.